{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import keras \n",
    "from skimage.transform import resize\n",
    "from keras.models import Sequential, Model, model_from_json\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function reads in a .dcm file, checks the important fields for our device, and returns a numpy array\n",
    "# of just the imaging data\n",
    "def check_dicom(filename): \n",
    "    # todo\n",
    "    \n",
    "#     print('Load file {} ...'.format(filename))\n",
    "#     ds = pydicom.dcmread(filename)       \n",
    "#     img = ds.pixel_array\n",
    "    dcm = pydicom.dcmread(filename)\n",
    "    \n",
    "    if dcm.Modality=='DX' and dcm.BodyPartExamined=='CHEST' and dcm.PatientPosition in ['PA','AP']:\n",
    "        img = dcm.pixel_array\n",
    "        return img\n",
    "    else:\n",
    "        print(\"The input file is not a valid dicom file.\")\n",
    "    \n",
    "    \n",
    "# This function takes the numpy array output by check_dicom and \n",
    "# runs the appropriate pre-processing needed for our model input\n",
    "def preprocess_image(img,img_mean,img_std,img_size): \n",
    "    # todo\n",
    "    proc_img = (img - img_mean) / img_std\n",
    "    proc_img = ImageDataGenertor(proc_img, img_size)\n",
    "    return proc_img\n",
    "\n",
    "# This function loads in our trained model w/ weights and compiles it \n",
    "def load_model(model_path, weight_path):\n",
    "    # todo\n",
    "    with open(model_path, \"r\") as json_file:\n",
    "        arch = json_file.read()\n",
    "    \n",
    "    model = model_from_json(arch)\n",
    "    model.load_weights(weight_path)\n",
    "        \n",
    "    return model\n",
    "\n",
    "# This function uses our device's threshold parameters to predict whether or not\n",
    "# the image shows the presence of pneumonia using our trained model\n",
    "def predict_image(model, img, thresh): \n",
    "    # todo \n",
    "    pred = model(img)\n",
    "    if pred>thresh:\n",
    "        return 'Positive'\n",
    "    else:\n",
    "        return 'Negative'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer sequential_1 was called with an input that isn't a symbolic tensor. Received type: <class 'numpy.ndarray'>. Full input: [array([[[[137.00091472, 137.00091472, 137.00091472],\n         [137.00091472, 137.00091472, 137.00091472],\n         [137.00091472, 137.00091472, 137.00091472],\n         ...,\n         [137.00091472, 137.00091472, 137.00091472],\n         [137.00091472, 137.00091472, 137.00091472],\n         [137.00091472, 137.00091472, 137.00091472]],\n\n        [[136.6213177 , 136.6213177 , 136.6213177 ],\n         [136.6213177 , 136.6213177 , 136.6213177 ],\n         [136.6213177 , 136.6213177 , 136.6213177 ],\n         ...,\n         [136.6213177 , 136.6213177 , 136.6213177 ],\n         [136.6213177 , 136.6213177 , 136.6213177 ],\n         [136.6213177 , 136.6213177 , 136.6213177 ]],\n\n        [[140.59893089, 140.59893089, 140.59893089],\n         [140.59893089, 140.59893089, 140.59893089],\n         [140.59893089, 140.59893089, 140.59893089],\n         ...,\n         [140.59893089, 140.59893089, 140.59893089],\n         [140.59893089, 140.59893089, 140.59893089],\n         [140.59893089, 140.59893089, 140.59893089]],\n\n        ...,\n\n        [[106.21181928, 106.21181928, 106.21181928],\n         [106.21181928, 106.21181928, 106.21181928],\n         [106.21181928, 106.21181928, 106.21181928],\n         ...,\n         [106.21181928, 106.21181928, 106.21181928],\n         [106.21181928, 106.21181928, 106.21181928],\n         [106.21181928, 106.21181928, 106.21181928]],\n\n        [[101.69994648, 101.69994648, 101.69994648],\n         [101.69994648, 101.69994648, 101.69994648],\n         [101.69994648, 101.69994648, 101.69994648],\n         ...,\n         [101.69994648, 101.69994648, 101.69994648],\n         [101.69994648, 101.69994648, 101.69994648],\n         [101.69994648, 101.69994648, 101.69994648]],\n\n        [[ 97.44882239,  97.44882239,  97.44882239],\n         [ 97.44882239,  97.44882239,  97.44882239],\n         [ 97.44882239,  97.44882239,  97.44882239],\n         ...,\n         [ 97.44882239,  97.44882239,  97.44882239],\n         [ 97.44882239,  97.44882239,  97.44882239],\n         [ 97.44882239,  97.44882239,  97.44882239]]]])]. All inputs to the layer should be tensors.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                 \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    696\u001b[0m         raise ValueError('Unexpectedly found an instance of type `' +\n\u001b[0;32m--> 697\u001b[0;31m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m                          'Expected a symbolic tensor instance.')\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'numpy.ndarray'>`. Expected a symbolic tensor instance.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-f14e4db7e591>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mimg_proc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_std\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_proc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-7b7acf51c4f6>\u001b[0m in \u001b[0;36mpredict_image\u001b[0;34m(model, img, thresh)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# todo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mthresh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'Positive'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# with the input_spec set at build time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;31m# Handle mask propagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                                  \u001b[0;34m'Received type: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full input: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. All inputs to the layer '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m                                  'should be tensors.')\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer sequential_1 was called with an input that isn't a symbolic tensor. Received type: <class 'numpy.ndarray'>. Full input: [array([[[[137.00091472, 137.00091472, 137.00091472],\n         [137.00091472, 137.00091472, 137.00091472],\n         [137.00091472, 137.00091472, 137.00091472],\n         ...,\n         [137.00091472, 137.00091472, 137.00091472],\n         [137.00091472, 137.00091472, 137.00091472],\n         [137.00091472, 137.00091472, 137.00091472]],\n\n        [[136.6213177 , 136.6213177 , 136.6213177 ],\n         [136.6213177 , 136.6213177 , 136.6213177 ],\n         [136.6213177 , 136.6213177 , 136.6213177 ],\n         ...,\n         [136.6213177 , 136.6213177 , 136.6213177 ],\n         [136.6213177 , 136.6213177 , 136.6213177 ],\n         [136.6213177 , 136.6213177 , 136.6213177 ]],\n\n        [[140.59893089, 140.59893089, 140.59893089],\n         [140.59893089, 140.59893089, 140.59893089],\n         [140.59893089, 140.59893089, 140.59893089],\n         ...,\n         [140.59893089, 140.59893089, 140.59893089],\n         [140.59893089, 140.59893089, 140.59893089],\n         [140.59893089, 140.59893089, 140.59893089]],\n\n        ...,\n\n        [[106.21181928, 106.21181928, 106.21181928],\n         [106.21181928, 106.21181928, 106.21181928],\n         [106.21181928, 106.21181928, 106.21181928],\n         ...,\n         [106.21181928, 106.21181928, 106.21181928],\n         [106.21181928, 106.21181928, 106.21181928],\n         [106.21181928, 106.21181928, 106.21181928]],\n\n        [[101.69994648, 101.69994648, 101.69994648],\n         [101.69994648, 101.69994648, 101.69994648],\n         [101.69994648, 101.69994648, 101.69994648],\n         ...,\n         [101.69994648, 101.69994648, 101.69994648],\n         [101.69994648, 101.69994648, 101.69994648],\n         [101.69994648, 101.69994648, 101.69994648]],\n\n        [[ 97.44882239,  97.44882239,  97.44882239],\n         [ 97.44882239,  97.44882239,  97.44882239],\n         [ 97.44882239,  97.44882239,  97.44882239],\n         ...,\n         [ 97.44882239,  97.44882239,  97.44882239],\n         [ 97.44882239,  97.44882239,  97.44882239],\n         [ 97.44882239,  97.44882239,  97.44882239]]]])]. All inputs to the layer should be tensors."
     ]
    }
   ],
   "source": [
    "test_dicoms = ['test1.dcm','test2.dcm','test3.dcm','test4.dcm','test5.dcm','test6.dcm']\n",
    "\n",
    "model_path = \"pneumonia_classifier_arch.json\"\n",
    "weight_path = \"pneumonia_classifier.best.hdf5\"\n",
    "\n",
    "# This might be different if you did not use vgg16\n",
    "IMG_SIZE=(1, 224,224,3) \n",
    "\n",
    "# loads the mean image value they used during training preprocessing\n",
    "img_mean = 0 \n",
    "\n",
    "# loads the std dev image value they used during training preprocessing\n",
    "img_std = 1 \n",
    "\n",
    "# loads model\n",
    "my_model = load_model(model_path, weight_path)\n",
    "\n",
    "#loads the threshold they chose for model classification \n",
    "thresh = 0.25\n",
    "\n",
    "# use the .dcm files to test your prediction\n",
    "for i in test_dicoms:\n",
    "    \n",
    "    img = np.array([])\n",
    "    img = check_dicom(i)\n",
    "    \n",
    "    if img is None:\n",
    "        continue\n",
    "        \n",
    "    img_proc = preprocess_image(img,img_mean,img_std,IMG_SIZE)\n",
    "    pred = predict_image(my_model, img_proc,thresh)\n",
    "    \n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()\n",
    "    print('Pred:' + pred + ' & Actual: ' + pydicom.dcmread(i).StudyDescription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
